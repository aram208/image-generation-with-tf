{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "arctic-installation",
   "metadata": {},
   "source": [
    "# Building a PixelCNN model from scratch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pressing-ideal",
   "metadata": {},
   "source": [
    "There are **three main categories** of deep neural network **generative** algorithms:\n",
    "- Generative Adversarial Networks\n",
    "- Variational Autoencoders\n",
    "- Autoregressive models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "entertaining-norman",
   "metadata": {},
   "source": [
    "## Autoregressive Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "grateful-orange",
   "metadata": {},
   "source": [
    "In machine learning terminology _regress_ means _predict new values_. I.e. \"autoregressive model\" means we use a model to predict new data points based on the model's past data points.\n",
    "\n",
    "An assumption we make here is that the value of a pixel depends only on that of the pixel before it. In other words, a pixel is conditioned only on the pixel before it, that is: $ p(x_i) = p(x_i | x_{i-1})p(x_{i-1}) $\n",
    "So, the joint probability will be the product of conditional probabilities:<br>\n",
    "$p(x)=p(x_n, x_{n-1}, ..., x_2, x_1)$\n",
    "<br>\n",
    "$p(x)=p(x_n|x_{n-1})...p(x_3|x_2)p(x_2|x_1)p(x_1)$\n",
    "\n",
    "_in simple words, say we have images with red apples surrounded by gree leaves. If a color of a pixel at (0,0) is green, the the probability that the next pixel's color at (0, 1) is green is high._"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "revolutionary-lighting",
   "metadata": {},
   "source": [
    "**PixelRNN** - recurrent NN based on LSTM. Reads the image one row at a time in a step in the LSTM and processes it with a 1D convo layer, then feeds the activations into subsequent layers. Slow. Fell out of fasion.\n",
    "\n",
    "**PixelCNN** - made up of convolutional layers, making it a lot faster than PixelRNN."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stable-cuisine",
   "metadata": {},
   "source": [
    "## PixelCNN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "healthy-arthritis",
   "metadata": {},
   "source": [
    "### Masking\n",
    "When performing a convolution to predict the current pixel, a conventional convolution kernel is able to see the current input pixel together with the surrounding pixels, including future pixels - this breaks our conditional probability assumption. \n",
    "To avoid that we use Masking - a mask is applied to the convolutional kernel weights before performing convolution (_see the pages 18-19 of the book for more details_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dominant-specific",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.activations import relu\n",
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib as plt\n",
    "\n",
    "from tqdm.keras import TqdmCallback\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from packaging.version import parse as parse_version\n",
    "assert parse_version(tf.__version__) < parse_version(\"2.5.1\"), \\\n",
    "    f\"Please install TensorFlow version 2.3.1 or older. Your current version is {tf.__version__}.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "collect-wednesday",
   "metadata": {},
   "source": [
    "### Load MNIST dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cleared-fellow",
   "metadata": {},
   "outputs": [],
   "source": [
    "(ds_train, ds_test), ds_info = tfds.load('mnist', split=['test', 'test'], shuffle_files=True, as_supervised=True, with_info=True)\n",
    "\n",
    "def binarize(image, label):\n",
    "    image = tf.cast(image, tf.float32)\n",
    "    image = tf.math.round(image/255.)\n",
    "    return image, tf.cast(image, tf.int32)\n",
    "\n",
    "ds_train = ds_train.map(binarize)\n",
    "ds_train = ds_train.cache() # put dataset into memory\n",
    "ds_train = ds_train.shuffle(ds_info.splits['train'].num_examples)\n",
    "ds_train = ds_train.batch(64)\n",
    "ds_test = ds_test.map(binarize).batch(64).cache().prefetch(64)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "remarkable-centre",
   "metadata": {},
   "source": [
    "### Create Custom Layers and PixelCNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "worthy-channels",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"PixelCnn\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 28, 28, 1)]       0         \n",
      "_________________________________________________________________\n",
      "masked_conv2d (MaskedConv2D) (None, 28, 28, 128)       6400      \n",
      "_________________________________________________________________\n",
      "residual_block (ResidualBloc (None, 28, 28, 128)       53504     \n",
      "_________________________________________________________________\n",
      "residual_block_1 (ResidualBl (None, 28, 28, 128)       53504     \n",
      "_________________________________________________________________\n",
      "residual_block_2 (ResidualBl (None, 28, 28, 128)       53504     \n",
      "_________________________________________________________________\n",
      "residual_block_3 (ResidualBl (None, 28, 28, 128)       53504     \n",
      "_________________________________________________________________\n",
      "residual_block_4 (ResidualBl (None, 28, 28, 128)       53504     \n",
      "_________________________________________________________________\n",
      "residual_block_5 (ResidualBl (None, 28, 28, 128)       53504     \n",
      "_________________________________________________________________\n",
      "residual_block_6 (ResidualBl (None, 28, 28, 128)       53504     \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (None, 28, 28, 64)        8256      \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 28, 28, 1)         65        \n",
      "=================================================================\n",
      "Total params: 389,249\n",
      "Trainable params: 389,249\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "class MaskedConv2D(layers.Layer):\n",
    "    def __init__(self, mask_type, kernel = 5, filters = 1):\n",
    "        super(MaskedConv2D, self).__init__()\n",
    "        self.kernel = kernel\n",
    "        self.filters = filters\n",
    "        self.mask_type = mask_type\n",
    "        \n",
    "    def build(self, input_shape):\n",
    "        \n",
    "        self.w = self.add_weight(shape=[self.kernel, \n",
    "                                        self.kernel, \n",
    "                                        input_shape[-1], \n",
    "                                        self.filters],\n",
    "                                 initializer='glorot_normal', \n",
    "                                 trainable=True)\n",
    "        \n",
    "        self.b = self.add_weight(shape=(self.filters,),\n",
    "                                initializer = 'zeros',\n",
    "                                trainable = True)\n",
    "        # Creating the Mask\n",
    "        mask = np.ones(self.kernel**2, dtype=np.float32)\n",
    "        center = len(mask)//2\n",
    "        mask[center+1:] = 0\n",
    "        if self.mask_type == 'A':\n",
    "            mask[center] = 0\n",
    "            \n",
    "        mask = mask.reshape((self.kernel, self.kernel, 1, 1))\n",
    "        \n",
    "        self.mask = tf.constant(mask, dtype='float32')\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        # mask the convolution\n",
    "        masked_w = tf.math.multiply(self.w, self.mask)\n",
    "        \n",
    "        # perform conv2d using low level API\n",
    "        output = tf.nn.conv2d(inputs, masked_w, 1, \"SAME\") + self.b\n",
    "        \n",
    "        return tf.nn.relu(output)\n",
    "    \n",
    "class ResidualBlock(layers.Layer):\n",
    "    def __init__(self, h=32):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "        \n",
    "        self.forward = Sequential([MaskedConv2D('B', kernel=1, filters=h),\n",
    "                                   MaskedConv2D('B', kernel=3, filters=h),\n",
    "                                   MaskedConv2D('B', kernel=1, filters=2*h)])\n",
    "\n",
    "    def call(self, inputs):\n",
    "        x = self.forward(inputs)\n",
    "        return x + inputs\n",
    "        \n",
    "def SimplePixelCnn(hidden_features = 64,\n",
    "                   output_features = 64,\n",
    "                   resblocks_num = 7):\n",
    "    \n",
    "    inputs = layers.Input(shape=[28, 28, 1])\n",
    "    x = inputs\n",
    "    \n",
    "    x = MaskedConv2D('A', kernel=7, filters=2*hidden_features)(x)\n",
    "    \n",
    "    for _ in range(resblocks_num):\n",
    "        x = ResidualBlock(hidden_features)(x)\n",
    "        \n",
    "    x = layers.Conv2D(output_features, (1, 1), padding='same', activation='relu')(x)\n",
    "    x = layers.Conv2D(1, (1, 1), padding='same', activation='sigmoid')(x)\n",
    "    \n",
    "    return tf.keras.Model(inputs=inputs, outputs=x, name='PixelCnn')\n",
    "\n",
    "pixel_cnn = SimplePixelCnn()\n",
    "pixel_cnn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "democratic-joining",
   "metadata": {},
   "outputs": [],
   "source": [
    "pixel_cnn.compile(\n",
    "    loss = tf.keras.losses.BinaryCrossentropy(),\n",
    "    optimizer=tf.keras.optimizers.RMSprop(learning_rate=0.001),\n",
    "    metrics=[tf.keras.losses.BinaryCrossentropy()])\n",
    "\n",
    "pixel_cnn.fit(ds_train, epochs = 50, validation_data=ds_test, callbacks=[TqdmCallback(verbose=1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "387180ac-2b87-4e48-bc5b-3242dd4a8d4a",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[0;34mc:\\users\\aram\\appdata\\local\\conda\\conda\\envs\\py37_tf\\lib\\site-packages\\IPython\\core\\interactiveshell.py\u001b[0m, in \u001b[0;32mrun_code\u001b[0m:\nLine \u001b[0;34m3437\u001b[0m:  exec(code_obj, \u001b[36mself\u001b[39;49;00m.user_global_ns, \u001b[36mself\u001b[39;49;00m.user_ns)\n",
      "In  \u001b[0;34m[1]\u001b[0m:\nLine \u001b[0;34m5\u001b[0m:     images = np.ones((batch,h,w,\u001b[34m1\u001b[39;49;00m), dtype=np.float32)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'np' is not defined\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m"
     ]
    }
   ],
   "source": [
    "grid_row = 5\n",
    "grid_col = 5\n",
    "batch = grid_row * grid_col\n",
    "h = w = 28\n",
    "images = np.ones((batch,h,w,1), dtype=np.float32)\n",
    "\n",
    "for row in range(h):\n",
    "\n",
    "    for col in range(w):\n",
    "\n",
    "        prob = pixel_cnn.predict(images)[:,row,col,0]\n",
    "\n",
    "        pixel_samples = tf.random.categorical(tf.math.log(np.stack([1-prob, prob],1)), 1)\n",
    "\n",
    "        images[:,row,col,0] = tf.reshape(pixel_samples,[batch])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "638016ac-4cb2-4ab9-a920-b5f032c54966",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display\n",
    "f, axarr = plt.subplots(grid_row, grid_col, figsize=(grid_col*1.1,grid_row))\n",
    "\n",
    "i = 0\n",
    "for row in range(grid_row):\n",
    "    for col in range(grid_col):\n",
    "        axarr[row,col].imshow(images[i,:,:,0], cmap='gray')\n",
    "        axarr[row,col].axis('off')\n",
    "        i += 1\n",
    "f.tight_layout(0.1, h_pad=0.2, w_pad=0.1)        \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c9bb82d-351a-4c5f-b471-c4a910f47e6f",
   "metadata": {},
   "source": [
    "## Sample and Display Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13683262-f3a3-45d2-a3ec-18a81eea7559",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_row = 5\n",
    "grid_col = 5\n",
    "batch = grid_row * grid_col\n",
    "h = w = 28\n",
    "images = np.ones((batch,h,w,1), dtype=np.float32)\n",
    "\n",
    "for row in range(h):\n",
    "\n",
    "    for col in range(w):\n",
    "\n",
    "        prob = pixel_cnn.predict(images)[:,row,col,0]\n",
    "\n",
    "        pixel_samples = tf.random.categorical(tf.math.log(np.stack([1-prob, prob],1)), 1)\n",
    "\n",
    "        images[:,row,col,0] = tf.reshape(pixel_samples,[batch])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ff65041-6bf2-4725-93b0-f28e2972b6a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display\n",
    "f, axarr = plt.subplots(grid_row, grid_col, figsize=(grid_col*1.1,grid_row))\n",
    "\n",
    "i = 0\n",
    "for row in range(grid_row):\n",
    "    for col in range(grid_col):\n",
    "        axarr[row,col].imshow(images[i,:,:,0], cmap='gray')\n",
    "        axarr[row,col].axis('off')\n",
    "        i += 1\n",
    "f.tight_layout(0.1, h_pad=0.2, w_pad=0.1)        \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7decaa1-8aae-45dc-9e2f-86da8503f5b2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
